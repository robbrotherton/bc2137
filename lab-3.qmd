# Lab 3: Data preparation {.unnumbered}

You will begin this session with variables from the ANES dataset in mind for your analysis. In class we will introduce the R language and RStudio environment, and demonstrate necessary data cleaning and manipulation in preparation for analysis. By the end of the class you should have modified the example code to work with your selected variables.

### Goals

-   Get your R environment set up
-   Read the data you need into R
-   Select required variables
-   Filter the data based on completeness (and any other criteria)
-   Compute any required variables (scale means, number of items missing, etc)
-   Describe and visualize your variables

## Working with data in R

### Getting R ready

In addition to being a source of high-quality data relevant to social psychology, the ANES dataset is convenient for our purposes because someone went to the trouble of creating an R package which makes working with the data relatively straightforward (not that you won't still run into issues!): `anesr` ([github.com/jamesmartherus/anesr](https://github.com/jamesmartherus/anesr)).

To start exploring the data in R, you first need to set up your environment. This means installing the `anesr` package. Usually packages can be installed from within R using the `install.packages()` function. However since the `anesr` package is hosted on GitHub (as opposed to the official R repository of packages), the easiest way to install it is by first installing the `devtools` package, which has a special function for installing packages from GitHub.

```{r}
#| eval: false

install.packages("devtools")

devtools::install_github("jamesmartherus/anesr")

```

We will also use some other packages for data wrangling and analysis. Developers have created a collection of packages for R called the `tidyverse` to make coding these common tasks easier. The `tidyverse` can be installed like so:

```{r}
#| eval: false

install.packages("tidyverse")

```

If you execute those lines of code the packages will be installed on your system. That step only needs to be done once, but you need to 'activate' the packages using `library()` to make their functions and data available each time to start a new R session.

```{r}
#| warning: false
#| message: false

library(anesr)
library(tidyverse)

```

### Getting data into R

Getting data into R often involves reading in a .csv (comma-separated values) spreadsheet file that you downloaded to your computer. Indeed, you could download the ANES data file as a .csv from the ANES website and read it into R that way. However, the `anesr` package contains the data so you don't need to download it separately. Instead you can make it available by running this line of code:

```{r}

data(timeseries_2020)

```

When you execute the code you won't see any output, but you should see the name `timeseries_2020` appear in your Environment pane. That is now an object in R called a data.frame. You can think of it as a spreadsheet like you're familiar with from Excel or Google Sheets; a set of columns, one for each variable in the dataset, and a row for each participant's answers.

Typing the name of the data.frame and running that line of code will show the first few columns and rows.

```{r}

timeseries_2020

```

You can also click on the name in the Environment pane to view the data in a new tab.

### Select your variables

As you can see, the data.frame contains a *lot* of variables; there are `r scales::label_comma()(ncol(timeseries_2020))` columns of data, one for each recorded variable. You'll only need two of those. So the first step is selecting just the variables you need to work with.

There are a lot of ways to do this. The simplest would be to make a note of the variable IDs from the codebook and use the `select()` function.[^tidyverse-note] This allows us to simply type in variable names separated by commas.

For this example code I'll look at two variables similar to those I had you pick from: trust in news media (In general, how much trust and confidence do you have in the news media when it comes to reporting the news fully, accurately, and fairly?) and perceived threat to the media (How concerned are you that some people in the government today might want to undermine the news mediaâ€™s ability to serve as a check on governmental power?). Their variable IDs are V201377 and V201376 respectively. Since I'll probably forget which ID is which, I'll give the columns more meaningful names as I select them.

```{r}

my_data <- timeseries_2020 |> 
  select(trust = V201377, 
         threat = V201376) |> 
  haven::zap_labels()

```

I did something else there as well: `haven::zap_labels()`. Even though when you look at the data it's a bunch of numbers, it's actually a special format called "haven-labelled", meaning there is some extra info stored about the numbers behind-the-scenes. That can be useful to have, but it actually interferes with some of the numeric filtering and mutating we need to do momentarily, so the `zap_labels()` function drops that label information and turns the data into plain old numbers.

Let's see what this new data.frame looks like:

```{r}
my_data
```

It all looks good so far. But if you inspect the data more extensively (click the name in your Environment to open a tab showing the data and scroll down a bit) you'll notice that there are some negative numbers in the data. You can see all the unique values recorded for a column in the data like so: 

```{r}
unique(my_data$trust)
```

The negatives are from survey codes which record missing data. If you try to calculate an average score with those included it'll mess up the sums, so we need to do some data cleaning to handle things like that.



### Cleaning the data

There are a lot of different ways we could handle this. One way is to `filter()` the data, retaining only rows which meet certain conditions.[^1]

The ANES coding scheme uses negative values for the various kinds of missing or inappropriate data, which makes things simple: only positive values are valid and should be retained.

To implement this as a `filter()`, we can use the `if_all()` function; i.e., we are going to select some columns and *if all* the values in those columns meet some condition the row will be retained. To select the columns we can use the `everything()` function, since the positive-valid/negative-invalid rule is true of every column in our data. The part after the comma, `~ . >= 0`, articulates the condition. The `~` prefix is necessary because instead of naming one specific column to refer to its values we use `.` as a placeholder representing the values in each of the selected columns; the value must be greater than or equal to 0 to be retained.[^2] 

```{r}
my_data_complete <- my_data |> 
  filter(if_all(everything(), ~ . >= 0))
```

Notice that the number of rows in the data.frame has changed, because rows that didn't meet that condition have been dropped.

```{r}
nrow(my_data)
nrow(my_data_complete) 
```

After filtering to keep only rows with complete data, we're left with `r format(nrow(my_data_complete), big.mark = ",")` valid responses.


### Recoding values

Now that we have selected our columns and filtered out missing/invalid responses, the last thing to do is recode values so they all mean what we want them to mean.

Notice that valid responses for the "undermine the news media" threat item are 1 (not at all concerned) through 5 (extremely concerned). I want higher scores on that question to indicate greater perceived threat, so that's fine. 

For the "trust in news media" question, responses are 1 (none) though 5 (a great deal). But I'm thinking of the psychological construct as *dis*trust rather than trust, so I want higher scores to indicate more distrust. The solution is simple: just recode the answers so that a score of 1 becomes a 5 (the most distrust), 2 becomes 4, 3 stays 3, 4 becomes 2 and 5 becomes 1 (the least distrust).


```{r}

my_data_complete <- my_data_complete |>
  mutate(distrust = 6 - trust)

```


Now I have my two variables, perceived threat to the news media, and (reverse-coded) distrust of the news media, for each of the `r scales::label_comma()(nrow(my_data_complete))` participants with complete data. We're ready to start exploring the data.


## Start examining the data

### Descriptive statistics

The most common descriptive statistics are the mean ($M$) and standard deviation ($SD$). You should report these for each variable in your analysis.

There are many ways of doing this, but for now I'll just use the `mean()` and `sd()` functions. I can refer to a particular column in a data.frame using the `$` operator, i.e. `my_data$threat` and so on.

```{r}
mean(my_data_complete$threat)
sd(my_data_complete$threat)

mean(my_data_complete$distrust)
sd(my_data_complete$distrust)
```


### Visualizing distributions

In addition to reporting the mean and standard deviation, it is useful to visualize the distribution of the data. This can reveal nuances that are not obvious in those single numeric summary values.

As with most things, there are a lot of different ways of producing graphs using R. One of the most widely used and powerful is the `ggplot2` package.^[The `ggplot2` package is part of the `tidyverse`, so because we already ran `library(tidyverse)` earlier the `ggplot2` functions are already available to us. If you needed to, you could always run `library(ggplot2)` to activate it separately.] The name refers to the idea of the "grammar of graphics", and it is built around a layering approach. You first specify your data and aesthetics (what should data will go on the x and y axes), then geometry (do you want data to be represented by points or bars or as a histogram?), any scaling (e.g. what values should be labeled on each axis), and theme elements (how do you want the plot to look generally?). There can be a lot of complexity, but building things up layer by layer, gradually adding and refining elements, is a powerful and satisfying approach.

Here's a simple histogram of the threat item. I pipe the data into the `ggplot()` function, specifying that I want the `threat` column to be represented as the `x` aesthetic. Then I add geometry using `geom_histogram`. That geom function automatically computes bins and counts; here I just specify I want a `binwidth` of 1, i.e. each column of the histogram will represent one scale point. Note that ggplot layers are added using `+` rather than the usual `|>` pipe.


```{r}
#| label: fig-threat-no-theme
#| fig-cap: Histogram of responses to perceived threat to news media question

my_data_complete |> 
  ggplot(aes(x = threat)) +
  geom_histogram(binwidth = 1)

```


The default theme is perfectly serviceable, but you can customize every element. Here I'll specify a couple of aspects using the `theme()` function, and I'll assign it to the name `theme_apa`. Then I can always add `theme_apa` as a layer to my plots going forward. 

```{r}

theme_apa <- theme(
  panel.background = element_blank(),
  axis.line = element_line()
)

```

I'll also customize the "breaks" and "labels" on the x-axis (to show the verbal scale responses rather than just numeric codes), and the labels for the x and y axes.

```{r}
#| label: fig-extraverted
#| fig-cap: Histogram of responses to perceived threat to news media

my_data_complete |> 
  ggplot(aes(x = threat)) +
  geom_histogram(binwidth = 1, color = "white") +
  scale_x_continuous(breaks = 1:5, 
                     labels = c(" Not at all", "A little", "Moderately", "Very", "Extremely")) +
  labs(x = "How concerned are you that some people in the government today might want to\nundermine the news mediaâ€™s ability to serve as a check on governmental power?",
       y = "Number of responses") +
  theme_apa

```

Here's a histogram of the distrust item.

```{r}
#| label: fig-distrust
#| fig-cap: Histogram of responses to "reserved, quiet" TIPI item

my_data_complete |> 
  ggplot(aes(x = distrust)) +
  geom_histogram(binwidth = 1, color = "white") +
  scale_x_continuous(breaks = 1:5,
                     labels = c("A great deal", "A lot", "A moderate amount", "A little", "None")) +
  labs(x = "In general, how much trust and confidence do you have in the news media \n when it comes to reporting the news fully, accurately, and fairly?",
       y = "Number of responses") +
  theme_apa

```



[^tidyverse-note]: The `select()` function, along with `filter()`, `mutate()`, `across()`, `everything()`, and others that you'll see in my example code, is part of the `tidyverse` family of packages (specifically these all come from the `dplyr` package, but we'll also use functions from other `tidyverse` packages like `tidyr` and `ggplot2`). There are other ways to do all these things without using `tidyverse` packages, just relying on what's referred to as "base" R functions. The `tidyverse` approach just makes this kind of data manipulation generally easier and makes the code more interpretable. If you're curious to see how base R and tidyverse functions differ in syntax, a good place to start is <https://dplyr.tidyverse.org/articles/base.html>.

[^1]: Another way would be to `mutate()` the data, changing the invalid response codes into the value `NA`, R's special value to indicate missing data. This could be achieved like so:

        my_data_complete <- my_data |>
          mutate(across(everything(), ~replace(., . < 0, NA)))

    That would mutate (i.e. change values) across every column. You can read the second part (after the `~`) as "replace the original values (indicated by the placeholder `.`), where the value is less than zero, with `NA`.

[^2]: If the data wasn't as simple or if we just wanted to be more explicit about things, we could filter based on valid responses for each item. For example, valid reponses to the feeling thermometer item are are anything from 0 to 100; anything else is invalid. Therefore we could write a `filter()` condition stating that `feeling_thermometer` (the name of the column) values must be `%in%` the set of values from `0:100`. Likewise for each of the extraversion columns, rows will be retained only if their values are `%in%` the range `1:7`.

        my_data_complete <- my_data |>
          filter(trust %in% 1:5,
                 threat %in% 1:5)




